{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e572ef3e",
   "metadata": {},
   "source": [
    "# Make dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd8d7c1",
   "metadata": {},
   "source": [
    "## 데이터 생성에서 사용된 아이디어\n",
    "1. contrastive learning의 개념을 적용하여 negative sample을 선정하였습니다.\n",
    "2. 학습할 모델보다 성능이 좋은 다른 모델(UniXcoder)을 이용해서 dataset을 sampling을 하였습니다. 이는 학습모델(GraphCodeBert)이 생각하지 못한 경우를 다른 모델로부터 배울 수 있다는 가정에서 접근하였습니다.\n",
    "3. 전처리는 간단하게 주석만 제거했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f4024a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffdd149",
   "metadata": {},
   "source": [
    "## code/problem\\*/\\*.py -> 전처리 -> preprocess-code.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b978bb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45101\n"
     ]
    }
   ],
   "source": [
    "file_names = glob.glob('../data/code/**/*.py')\n",
    "print(len(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f1c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(lines):\n",
    "    l = []\n",
    "    for line in lines:\n",
    "        # 주석으로 시작하는 줄 제거\n",
    "        if line.lstrip().startswith('#'):\n",
    "            continue\n",
    "            \n",
    "        # isBlank\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # 우측 주석 제거\n",
    "        line = line.rstrip()\n",
    "        if '#' in line:\n",
    "            line = line[:line.rindex('#')]\n",
    "        \n",
    "        l.append(line)\n",
    "    return ' '.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "511c706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for file_name in file_names:\n",
    "    lines = open(file_name).read().splitlines()\n",
    "    t = {\n",
    "        'problem_no': int(file_name.split('/')[-2][7:]),\n",
    "        'code_no': int(file_name.split('/')[-1].split('_')[1][:-3]),\n",
    "        'code': preprocess(lines)\n",
    "    }\n",
    "    l.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e095679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>problem_no</th>\n",
       "      <th>code_no</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M = 9 N = 9 def main():     for i in range(1,M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>for i in range(1,10):     for j in range(1,10)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>for i in range(1, 10): \\tfor ii in range(1, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>for a in range(1,10):     for b in range(1,10)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>for a in range(1,10):     for b in range(1,10)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45096</th>\n",
       "      <td>45096</td>\n",
       "      <td>300</td>\n",
       "      <td>146</td>\n",
       "      <td>def main():   A,B = map(int,input().split())  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45097</th>\n",
       "      <td>45097</td>\n",
       "      <td>300</td>\n",
       "      <td>147</td>\n",
       "      <td>A, B = list(map(int, input().split())) import ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45098</th>\n",
       "      <td>45098</td>\n",
       "      <td>300</td>\n",
       "      <td>148</td>\n",
       "      <td>A, B = map(int, input().split()) def factoriza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45099</th>\n",
       "      <td>45099</td>\n",
       "      <td>300</td>\n",
       "      <td>149</td>\n",
       "      <td>import math def gcd(a, b):     if (b == 0):   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45100</th>\n",
       "      <td>45100</td>\n",
       "      <td>300</td>\n",
       "      <td>150</td>\n",
       "      <td>from fractions import gcd def factor(n):     r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45101 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  problem_no  code_no  \\\n",
       "0          0           1        1   \n",
       "1          1           1        2   \n",
       "2          2           1        3   \n",
       "3          3           1        4   \n",
       "4          4           1        5   \n",
       "...      ...         ...      ...   \n",
       "45096  45096         300      146   \n",
       "45097  45097         300      147   \n",
       "45098  45098         300      148   \n",
       "45099  45099         300      149   \n",
       "45100  45100         300      150   \n",
       "\n",
       "                                                    code  \n",
       "0      M = 9 N = 9 def main():     for i in range(1,M...  \n",
       "1      for i in range(1,10):     for j in range(1,10)...  \n",
       "2      for i in range(1, 10): \\tfor ii in range(1, 10...  \n",
       "3      for a in range(1,10):     for b in range(1,10)...  \n",
       "4      for a in range(1,10):     for b in range(1,10)...  \n",
       "...                                                  ...  \n",
       "45096  def main():   A,B = map(int,input().split())  ...  \n",
       "45097  A, B = list(map(int, input().split())) import ...  \n",
       "45098  A, B = map(int, input().split()) def factoriza...  \n",
       "45099  import math def gcd(a, b):     if (b == 0):   ...  \n",
       "45100  from fractions import gcd def factor(n):     r...  \n",
       "\n",
       "[45101 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_code_all = pd.DataFrame.from_dict(l)\n",
    "df_code_all = df_code_all.sort_values(by=['problem_no', 'code_no'], axis=0)\n",
    "df_code_all = df_code_all.reset_index(drop=True)\n",
    "df_code_all = df_code_all.reset_index()\n",
    "df_code_all.to_csv('./dataset/preprocess-code.csv')\n",
    "df_code_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c6165",
   "metadata": {},
   "source": [
    "## jsonl 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ff9cf338",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for idx in range(len(df_code_all)):\n",
    "    d = {\n",
    "        'func': df_code_all.iloc[idx]['code'],\n",
    "        'idx': str(df_code_all.iloc[idx]['index'])\n",
    "    }\n",
    "    l.append(d)\n",
    "\n",
    "with jsonlines.open('./dataset/data.jsonl', mode='w') as writer:\n",
    "    writer.write_all(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "c16702ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'func': 'M = 9 N = 9 def main():     for i in range(1,M+1,1):         for j in range(1,N+1,1):             mult = i * j             print(str(i) + \"x\" + str(j) + \"=\" + str(i * j)) main()', 'idx': '0'}\n",
      "M = 9 N = 9 def main():     for i in range(1,M+1,1):         for j in range(1,N+1,1):             mult = i * j             print(str(i) + \"x\" + str(j) + \"=\" + str(i * j)) main()\n",
      "0\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "with jsonlines.open('./dataset/data.jsonl') as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        print(line['func'])\n",
    "        print(line['idx'])\n",
    "        print(type(line['idx']))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0bcfe7",
   "metadata": {},
   "source": [
    "## train/valid pair sampling\n",
    "\n",
    "- 가진 데이터는 300개의 문제에 대해서 소스코드가 150개씩 있습니다.\n",
    "- train과 valid set을 8:2로 분리합니다.\n",
    "- 문제 번호(problem_no) 간 데이터 비율을 유지하기 위해서 코드 번호(code_no)를 기준으로 train과 valid를 구분하였습니다.\n",
    "- 코드 번호(code_no)를 기준으로 120번 이하는 train, 그 외는 valid로 분리하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd01078c",
   "metadata": {},
   "source": [
    "###  negative pair sampling based UniXcoder\n",
    "\n",
    "- negative sample을 선정합니다.\n",
    "- contrastive learning 일부 개념을 적용하였습니다.\n",
    "    - 벡터 공간에서 negative pair는 멀게, positive pair는 가깝게\n",
    "- [UniXcoder](https://github.com/microsoft/CodeBERT/tree/master/UniXcoder)를 인코더로 이용하여 모든 코드를 동일한 벡터공간에 표현하였습니다.\n",
    "- 하나의 코드에 대해서 cosine similarity가 높지만 label이 0 코드와 cosine similarty가 0 이하지만 label이 1인 코드를 negative pair로 선택하였습니다.\n",
    "- 데이터 갯수와 학습시간은 비례하기때문에 negative sample 개수는 하나의 문제당 (전체 문제 수 x 0.0003)개를 선택했습니다. \n",
    "- 총 120 x 300 x 11 = 396,000개 중에서 중복제거를 통해 340,071개의 negative pair for training을 선정했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f974f2",
   "metadata": {},
   "source": [
    "### positive pair sampling - chaining + random\n",
    "- positive pair sampling은 chaining으로 일부를 생성하고, negative pair와 수를 맞추기위해 나머지를 random sampling으로 채웠습니다.\n",
    "- chaining\n",
    "    - chaining은 제가 명명한 것입니다.\n",
    "    - 코드를 순서대로 2개씩 pairing하는 것이 chain과 같아서 chaining이라고 명명하였습니다.\n",
    "    - 하나의 pair를 (문제번호-코드번호, 문제번호-코드번호) 라고 표현한다면 (1-1,1-2), (1-2,1-3) ..이런식으로 pair를 구성하였습니다.\n",
    "    - chaining을 통해 모든 문제가 최소 1번은 positive data에 추가되도록 하였습니다.\n",
    "- negative sampling과 수를 맞추기위하여 len(negative_sample) - len(positive_chain_sample) 만큼 random pair를 선택하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0670c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/microsoft/CodeBERT/master/UniXcoder/unixcoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9685627b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniXcoder(\n",
       "  (model): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(51416, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(1026, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(10, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=51416, bias=False)\n",
       "  (lsm): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unixcoder import UniXcoder\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UniXcoder(\"microsoft/unixcoder-base\")\n",
    "# model = UniXcoder(\"microsoft/unixcoder-base-unimodal\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec3d3c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import combinations\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "def make_data(df_set, set_number, dataset_type):\n",
    "    code_embeddings = []\n",
    "    for text in tqdm(df_set['code']):\n",
    "        tokens_ids = model.tokenize([text],max_length=512,mode=\"<encoder-only>\")\n",
    "        source_ids = torch.tensor(tokens_ids).to(device)\n",
    "        _, code_embedding = model(source_ids)\n",
    "        code_embeddings.append(code_embedding.cpu().detach().numpy()[0])\n",
    "    cos_sim = cosine_similarity(code_embeddings)\n",
    "\n",
    "    negative_samples = []\n",
    "    for i in tqdm(range(len(cos_sim))):\n",
    "        problem_nos = list(df_set['problem_no'])\n",
    "        problem_no = problem_nos[i]\n",
    "        temp_list = []\n",
    "        index_asc = np.argsort(cos_sim[i])\n",
    "        for index in index_asc[::-1]: # 내림차순\n",
    "            c = cos_sim[i][index]\n",
    "            if (c > 0 and problem_nos[index] != problem_no):\n",
    "                temp_list.append([i, index])\n",
    "            if len(temp_list) > len(cos_sim)*0.0003:\n",
    "                break\n",
    "        for index in index_asc: # 오름차순\n",
    "            c = cos_sim[i][index]\n",
    "            if c > 0:\n",
    "                break\n",
    "            if (c <= 0 and problem_nos[index] == problem_no):\n",
    "                temp_list.append([i, index])\n",
    "\n",
    "        negative_samples.extend(temp_list)\n",
    "\n",
    "    temp_negative_samples = []\n",
    "    for s in negative_samples:\n",
    "        s.sort()\n",
    "        temp_negative_samples.append(s)\n",
    "    \n",
    "    temp_negative_samples.sort()\n",
    "    negative_samples = (list(k for k,_ in itertools.groupby(temp_negative_samples)))\n",
    "    print('negative samples', len(negative_samples))\n",
    "        \n",
    "    ## Positive pair sampling\n",
    "    \n",
    "    positive_pairs_chain = []\n",
    "\n",
    "    def make_positive_chain_pair(df):\n",
    "        for i in range(len(df['index'])-1):\n",
    "            positive_pairs_chain.append((df.iloc[i]['index'], df.iloc[i+1]['index']))\n",
    "        positive_pairs_chain.append((df.iloc[i]['index'], df.iloc[0]['index']))\n",
    "        \n",
    "    df_set.groupby('problem_no').apply(make_positive_chain_pair)\n",
    "    print('positive chain', len(positive_pairs_chain))\n",
    "        \n",
    "    positive_pairs_all = []\n",
    "    positive_pairs_random = []\n",
    "    \n",
    "    def make_positive_pair(df):\n",
    "        comb = list(combinations(df['index'], 2))\n",
    "        positive_pairs_all.extend(comb)\n",
    "        random.seed(5)\n",
    "        max_len = (len(negative_samples)-len(positive_pairs_chain)) // (len(set(df_set['problem_no']))-1)\n",
    "        positive_pairs_random.extend(random.choices(comb, k=min(max_len, len(comb))))\n",
    "        \n",
    "    df_set.groupby('problem_no').apply(make_positive_pair)\n",
    "    print('positive random samples', len(positive_pairs_random), 'all', len(positive_pairs_all))\n",
    "        \n",
    "    positive_samples = positive_pairs_chain + positive_pairs_random\n",
    "    print('positivie samples', len(positive_samples))\n",
    "    \n",
    "    positive_df = pd.DataFrame(positive_samples, columns=['id1', 'id2'])\n",
    "    positive_df['label'] = 1\n",
    "    negative_df = pd.DataFrame(negative_samples, columns=['id1', 'id2'])\n",
    "    negative_df['label'] = 0\n",
    "    \n",
    "    df = pd.concat([positive_df, negative_df])\n",
    "    df = shuffle(df)\n",
    "    \n",
    "    print('total samples', len(df))\n",
    "    \n",
    "    df.to_csv('./dataset/{}-{}.txt'.format(dataset_type, set_number), sep='\\t', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d0118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 36000/36000 [06:49<00:00, 87.87it/s]\n",
      "100%|████████████████████████████████████| 36000/36000 [03:20<00:00, 179.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative samples 340071\n",
      "positive chain 36000\n",
      "positive random samples 304800 all 2142000\n",
      "positivie samples 340800\n",
      "total samples 680871\n"
     ]
    }
   ],
   "source": [
    "# train dataset\n",
    "df_train = df_code_all[(df_code_all['code_no'] <= 120)]\n",
    "make_data(df_train, 0, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "482ae529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 9101/9101 [01:36<00:00, 94.71it/s]\n",
      "100%|██████████████████████████████████████| 9101/9101 [00:12<00:00, 745.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative samples 23647\n",
      "positive chain 9101\n",
      "positive random samples 14400 all 133546\n",
      "positivie samples 23501\n",
      "total samples 47148\n"
     ]
    }
   ],
   "source": [
    "# valid dataset\n",
    "df_valid = df_code_all[(df_code_all['code_no'] > 120)]\n",
    "make_data(df_valid, 0, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b25e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
